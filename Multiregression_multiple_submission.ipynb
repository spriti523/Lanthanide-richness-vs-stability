{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "185089f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import all the libraries for\n",
    "#numpy,pandas,sklearn,matplotlib are the primary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "#from feature_vector import gen_test, gen_train\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output\n",
    "clear_output()\n",
    "#svm and with cross validation\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from IPython.display import clear_output\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from sklearn import preprocessing\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da182ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_lanth(A,B):\n",
    "    \n",
    "    # 80% test train split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                       A, B,test_size=0.2)\n",
    "    rows=np.shape(x_test)[0]\n",
    "    cols=np.shape(y_test)[1]\n",
    "    ytest_clf=np.zeros((rows,cols))\n",
    "    \n",
    "    # Tuning parameters: estimator__gamma,estimator__C\n",
    "    tuned_parameters = [  {\"estimator__kernel\": [\"rbf\"], \"estimator__gamma\": [1e-3, 1e-4], \"estimator__C\": [1, 10, 100, 1000]}]\n",
    "\n",
    "    \n",
    "    ## Defining the regressor for SVR: For multiple output\n",
    "    mor=MultiOutputRegressor(SVR())\n",
    "    \n",
    "    #Gridsearching to get the best parameter(s) with 5-fold cross validation\n",
    "    clf=GridSearchCV(mor,tuned_parameters,scoring=\"neg_mean_squared_error\",cv=5).fit(x_train, y_train)\n",
    "    \n",
    "    # Getting the best parameters. estimator__gamma in this case\n",
    "    best_param=clf.cv_results_['params'][clf.best_index_]\n",
    "    \n",
    "    #Training \n",
    "    nmor=MultiOutputRegressor(SVR(kernel='rbf',C=best_param['estimator__C'],gamma=best_param['estimator__gamma']))\n",
    "    \n",
    "    #for prediction\n",
    "    tlf = nmor.fit(x_train, y_train)\n",
    "    \n",
    "    #for permutation importance\n",
    "    #tlf=nmor.fit(A,B)\n",
    "    \n",
    "    \n",
    "    #Testing with full data A,B for importance \n",
    "    #result = permutation_importance(tlf, x_train, y_train, n_repeats=5)\n",
    "    \n",
    "    # Prediction\n",
    "    ytest_clf=tlf.predict(x_test)\n",
    "    \n",
    "    #returning squared error\n",
    "    return(np.mean((ytest_clf-y_test)**2)) \n",
    "\n",
    "def kernel_rid_lanth(A,B):\n",
    "    \n",
    "    # 80% test train split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                       A, B,test_size=0.2)\n",
    "    rows=np.shape(x_test)[0]\n",
    "    cols=np.shape(y_test)[1]\n",
    "    ytest_clf=np.zeros((rows,cols))\n",
    "    \n",
    "    \n",
    "     # Tuning parameters: estimator__alpha,estimator__kernel,estimator__gamma\n",
    "    tuned_parameters = {\"estimator__alpha\":[0.1,0.001,0.00001],\"estimator__kernel\":[\"rbf\",\"linear\",\"polynomial\"],\n",
    "            \"estimator__gamma\": [1e-3, 1e-4]}\n",
    "\n",
    "    \n",
    "    ## Defining the regressor for Kernel Ridge : Multiple output\n",
    "    mor=MultiOutputRegressor(KernelRidge())\n",
    "    clf=GridSearchCV(mor,tuned_parameters,scoring=\"neg_mean_squared_error\",cv=5).fit(x_train, y_train) #fit(A,B)#.fit(x_train, y_train)\n",
    "\n",
    "    # Getting the best parameters. estimator__gamma in this case\n",
    "    best_param=clf.cv_results_['params'][clf.best_index_]\n",
    "    nmor=MultiOutputRegressor(KernelRidge(kernel=best_param['estimator__kernel'],alpha=best_param['estimator__alpha'],gamma=best_param['estimator__gamma']))\n",
    "    \n",
    "    #Testing with full data A,B for importance\n",
    "    #tlf=nmor.fit(A,B)\n",
    "    #result = permutation_importance(tlf, A,B, n_repeats=5)\n",
    "    \n",
    "      \n",
    "    #Training with test-train\n",
    "    tlf=nmor.fit(x_train, y_train)\n",
    "    #Prediction\n",
    "    ytest_clf=tlf.predict(x_test)\n",
    "    \n",
    "    #Squared error\n",
    "    return(np.mean((ytest_clf-y_test)**2))\n",
    "\n",
    "    #return(result)\n",
    "\n",
    "def neural_net_lanth_2(A,B):\n",
    "    # 80% test train split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                       A, B,test_size=0.2)\n",
    "    rows=np.shape(x_test)[0]\n",
    "    cols=np.shape(y_test)[1]\n",
    "    ytest_clf=np.zeros((rows,cols))\n",
    "    \n",
    "     # Tuning parameters: estimator__hidden_layer_sizes\n",
    "    tuned_parameters = {\"estimator__activation\": [\"logistic\"],\n",
    "               \"estimator__solver\":[\"lbfgs\"],\n",
    "               \"estimator__hidden_layer_sizes\":[10,20,30,40,50],\n",
    "               \"estimator__alpha\":[0.001], \"estimator__learning_rate\":[\"constant\"] }\n",
    "\n",
    "    ## Defining the regressor for Neural Network : Multiple output\n",
    "    mor= MultiOutputRegressor(MLPRegressor())\n",
    "    clf=GridSearchCV(mor, tuned_parameters,scoring=\"neg_mean_squared_error\",cv=2).fit(x_train,y_train)\n",
    "    \n",
    "    # Getting the best parameters.\n",
    "    best_param=clf.cv_results_['params'][clf.best_index_]\n",
    "    nmor=MultiOutputRegressor(MLPRegressor(alpha=best_param['estimator__alpha'],hidden_layer_sizes=best_param['estimator__hidden_layer_sizes'],activation='identity', solver='lbfgs',learning_rate='constant'))\n",
    "    tlf =nmor.fit(x_train, y_train)\n",
    "    \n",
    "   #Prediction\n",
    "    ytest_clf=tlf.predict(x_test)\n",
    "    \n",
    "    #Testing with full data A,B for importance\n",
    "    #tlf=nmor.fit(A,B)\n",
    "    #result = permutation_importance(tlf, A,B, n_repeats=5)\n",
    "    \n",
    "    #Squared error\n",
    "    return(np.mean((ytest_clf-y_test)**2))\n",
    "    #return(result)\n",
    "    \n",
    "def random_forest_lanth(A,B):\n",
    "    # 80% test train split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(A, B,test_size=0.2)\n",
    "    rows=np.shape(x_test)[0]\n",
    "    cols=np.shape(y_test)[1]\n",
    "    ytest_clf=np.zeros((rows,cols))\n",
    "    \n",
    "     # Tuning parameters:estimator__n_estimators,estimator__max_samples\n",
    "    tuned_parameters = [  {\"estimator__n_estimators\": [20,30,40], \"estimator__criterion\": [\"poisson\"], \"estimator__max_samples\": [100, 200]}]\n",
    "\n",
    "    ## Defining the regressor for Neural Network : Multiple output\n",
    "    mor=MultiOutputRegressor(RandomForestRegressor())\n",
    "    clf=GridSearchCV(mor,tuned_parameters,scoring=\"neg_mean_squared_error\",cv=4)#.fit(A,B)#fit(A,B)#\n",
    "    #clf.fit(A,B.iloc[:])\n",
    "    clf.fit(x_train,y_train)\n",
    "    \n",
    "    # Getting the best parameters.\n",
    "    best_param=clf.cv_results_['params'][clf.best_index_]\n",
    "    nmor=MultiOutputRegressor(RandomForestRegressor(n_estimators=best_param['estimator__n_estimators'],max_samples=best_param['estimator__max_samples']))\n",
    "    tlf =nmor.fit(x_train,y_train)#fit(A,B) #fit(x_train,y_train) #fit(A,B.iloc[:])\n",
    "    \n",
    "    #Testing with full data A,B for importance\n",
    "    #tlf=nmor.fit(A,B)\n",
    "    #result = permutation_importance(tlf, A,B, n_repeats=5)\n",
    "    \n",
    "    #Prediction\n",
    "    ytest_clf=tlf.predict(x_test)\n",
    "    \n",
    "    #Squared error\n",
    "    return(np.mean((ytest_clf-y_test)**2)) \n",
    "    #return(result)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f2e04c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed loop 0\n",
      "completed loop 1\n",
      "completed loop 2\n",
      "completed loop 3\n",
      "completed loop 4\n",
      "completed loop 5\n",
      "completed loop 6\n",
      "completed loop 7\n",
      "completed loop 8\n",
      "completed loop 9\n",
      "completed loop 10\n",
      "completed loop 11\n",
      "completed loop 12\n",
      "completed loop 13\n",
      "completed loop 14\n",
      "completed loop 15\n",
      "completed loop 16\n",
      "completed loop 17\n",
      "completed loop 18\n",
      "completed loop 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel_Ridge</th>\n",
       "      <th>random_forest</th>\n",
       "      <th>svm</th>\n",
       "      <th>neural_net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.000618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>0.000660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>0.000688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>0.000596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.000650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.000637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>0.000573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.002678</td>\n",
       "      <td>0.000827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.000734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.000563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.000687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.002629</td>\n",
       "      <td>0.000588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.003051</td>\n",
       "      <td>0.000699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>0.000907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>0.000584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.002798</td>\n",
       "      <td>0.000604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>0.000687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.000694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.000588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Kernel_Ridge  random_forest       svm  neural_net\n",
       "0       0.000547       0.000396  0.003049    0.000618\n",
       "1       0.000454       0.000336  0.002833    0.000660\n",
       "2       0.000450       0.000547  0.002679    0.000688\n",
       "3       0.000438       0.000398  0.002513    0.000596\n",
       "4       0.000450       0.000378  0.002900    0.000650\n",
       "5       0.000498       0.000399  0.002625    0.000637\n",
       "6       0.000566       0.000380  0.002661    0.000573\n",
       "7       0.000499       0.000501  0.002678    0.000827\n",
       "8       0.000520       0.000576  0.002853    0.000734\n",
       "9       0.000406       0.000550  0.002706    0.000563\n",
       "10      0.000444       0.000318  0.002844    0.000687\n",
       "11      0.000442       0.000354  0.002629    0.000588\n",
       "12      0.000397       0.000381  0.002853    0.000572\n",
       "13      0.000457       0.000430  0.003051    0.000699\n",
       "14      0.000465       0.000491  0.002811    0.000907\n",
       "15      0.000390       0.000358  0.002733    0.000584\n",
       "16      0.000443       0.000355  0.002798    0.000604\n",
       "17      0.000466       0.000549  0.002908    0.000687\n",
       "18      0.000507       0.000515  0.003063    0.000694\n",
       "19      0.000416       0.000533  0.002655    0.000588"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from sklearn import preprocessing\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "clear_output()\n",
    "\n",
    "# Loading the screened X and Y matrices. \n",
    "x_screened=pd.read_csv('/Users/sampreetibhattacharya/Documents/vestalab/ML_proj/X_screen_mapped.csv')\n",
    "ytr=pd.read_csv('/Users/sampreetibhattacharya/Documents/vestalab/ML_proj/Y.csv')\n",
    "\n",
    "x_screen_new=pd.DataFrame(np.matrix(x_screened.iloc[:,1:]),columns=x_screened.columns[1:])\n",
    "ytr_new=pd.DataFrame(np.matrix(ytr.iloc[:,1:]),columns=ytr.columns[1:])\n",
    "\n",
    "# Defining error vec matrix with 20 runs for each four methods, SVM, Kernel Ridge,\n",
    "#NeuralNetwork and Random Forest\n",
    "\n",
    "error_vec=np.zeros((20,4))\n",
    "\n",
    "# scale the response and the predictors\n",
    "scaler = preprocessing.MinMaxScaler().fit(ytr_new)\n",
    "y_scaled=scaler.transform(ytr_new)            \n",
    "scaler = preprocessing.MinMaxScaler().fit(x_screen_new.iloc[:,:])\n",
    "new_x_screened=pd.DataFrame(scaler.transform(x_screen_new.iloc[:,:]),columns=x_screen_new.columns)                                                 # huge among each other\n",
    "\n",
    "#running times for reproducibility\n",
    "for j in range(0,20):\n",
    "    error_vec[j,0]=kernel_rid_lanth(new_x_screened,y_scaled)\n",
    "    error_vec[j,1]=random_forest_lanth(new_x_screened,y_scaled)\n",
    "    error_vec[j,2]=svm_lanth(new_x_screened,y_scaled) \n",
    "    error_vec[j,3]=neural_net_lanth_2(x_screen_new,y_scaled)\n",
    "    print(\"completed loop\",j)\n",
    "    \n",
    "\n",
    "## Storing the errors\n",
    "pd.DataFrame(error_vec,columns=[\"Kernel_Ridge\",\"random_forest\",\"svm\",\"neural_net\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b17f249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00046263, 0.00043736, 0.00279209, 0.00065784])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the pooled mean, in error_vec[0:Kernel Ridge,random forest, svm , neural networj]\n",
    "error_vec.mean(axis=0)\n",
    "#Random Forest gives the minimum error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a2c99b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose the model to get the importance mean\n",
    "# and uncomment lines needed for variable importance.\n",
    "def random_forest_lanth(A,B):\n",
    "    # 80% test train split\n",
    "    #x_train, x_test, y_train, y_test = train_test_split(A, B,test_size=0.2)\n",
    "#     rows=np.shape(A)[0]\n",
    "#     cols=np.shape(B)[1]\n",
    "#     ytest_clf=np.zeros((rows,cols))\n",
    "    \n",
    "     # Tuning parameters:estimator__n_estimators,estimator__max_samples\n",
    "    tuned_parameters = [  {\"estimator__n_estimators\": [20,30,40], \"estimator__criterion\": [\"poisson\"], \"estimator__max_samples\": [100, 200]}]\n",
    "\n",
    "    ## Defining the regressor for Neural Network : Multiple output\n",
    "    mor=MultiOutputRegressor(RandomForestRegressor())\n",
    "    clf=GridSearchCV(mor,tuned_parameters,scoring=\"neg_mean_squared_error\",cv=4)#.fit(A,B)#fit(A,B)#\n",
    "    clf.fit(A,B)\n",
    "    #clf.fit(x_train,y_train)\n",
    "    \n",
    "    # Getting the best parameters.\n",
    "    best_param=clf.cv_results_['params'][clf.best_index_]\n",
    "    nmor=MultiOutputRegressor(RandomForestRegressor(n_estimators=best_param['estimator__n_estimators'],max_samples=best_param['estimator__max_samples']))\n",
    "    #tlf =nmor.fit(x_train,y_train)#fit(A,B) #fit(x_train,y_train) #fit(A,B.iloc[:])\n",
    "    \n",
    "    #Testing with full data A,B for importance\n",
    "    tlf=nmor.fit(A,B)\n",
    "    result = permutation_importance(tlf, A,B, n_repeats=5)\n",
    "    \n",
    "    #Prediction\n",
    "    #ytest_clf=tlf.predict(x_test)\n",
    "    \n",
    "    #Squared error\n",
    "    #return(np.mean((ytest_clf-y_test)**2)) \n",
    "    return(result)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f09c37f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in loop  0\n",
      "in loop  1\n",
      "in loop  2\n",
      "in loop  3\n",
      "in loop  4\n",
      "in loop  5\n",
      "in loop  6\n",
      "in loop  7\n",
      "in loop  8\n",
      "in loop  9\n"
     ]
    }
   ],
   "source": [
    "### Permutation importance code for random forest ######\n",
    "\n",
    "# Permuting columns to ensure robustness\n",
    "l=np.random.permutation(x_screen_new.columns)\n",
    "xl=x_screen_new[l] # to permute the columns\n",
    "\n",
    "## Defining the importance array \n",
    "importance_rf=np.zeros((10,100))\n",
    "\n",
    "for i in range(0,10):\n",
    "    print(\"in loop \",i)\n",
    "    importance=random_forest_lanth(xl,y_scaled)\n",
    "    importance_rf[i,:]=np.transpose(importance.importances_mean)\n",
    "\n",
    "importance_rf_final=pd.DataFrame(importance_rf,columns=xl.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3ec6852a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6.524636e-01</th>\n",
       "      <td>Asite_shannon_radii_weighted_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.128266e-01</th>\n",
       "      <td>Bsite_shannon_radii_weighted_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.544867e-01</th>\n",
       "      <td>Bsite_Ionic Radius (angstroms)_weighted_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.901397e-01</th>\n",
       "      <td>shannon_radii_AB_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.395373e-05</th>\n",
       "      <td>Bsite_IsMetal_weighted_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.951802e-09</th>\n",
       "      <td>Bsite_IsTetragonal_range</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-3.270981e-08</th>\n",
       "      <td>host_Asite0_IsPnictide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-4.166642e-08</th>\n",
       "      <td>Bsite_OrbitalS_range</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1.589878e-07</th>\n",
       "      <td>Bsite_IsOrthorhombic_min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-7.011864e-07</th>\n",
       "      <td>Bsite_IsTransition Metal_max</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         0\n",
       " 6.524636e-01             Asite_shannon_radii_weighted_avg\n",
       " 6.128266e-01             Bsite_shannon_radii_weighted_avg\n",
       " 3.544867e-01  Bsite_Ionic Radius (angstroms)_weighted_avg\n",
       " 2.901397e-01                         shannon_radii_AB_avg\n",
       " 9.395373e-05                   Bsite_IsMetal_weighted_avg\n",
       "...                                                    ...\n",
       " 6.951802e-09                     Bsite_IsTetragonal_range\n",
       "-3.270981e-08                       host_Asite0_IsPnictide\n",
       "-4.166642e-08                         Bsite_OrbitalS_range\n",
       "-1.589878e-07                     Bsite_IsOrthorhombic_min\n",
       "-7.011864e-07                 Bsite_IsTransition Metal_max\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indx=importance_rf_final.mean(axis=0).argsort()[::-1]\n",
    "pd.DataFrame(importance_rf_final.columns[indx],importance_rf_final.mean(axis=0)[indx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "63edf8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_rid_lanth(A,B):\n",
    "    \n",
    "\n",
    "     # Tuning parameters: estimator__alpha,estimator__kernel,estimator__gamma\n",
    "    tuned_parameters = {\"estimator__alpha\":[0.1,0.001,0.00001],\"estimator__kernel\":[\"rbf\",\"linear\",\"polynomial\"],\n",
    "            \"estimator__gamma\": [1e-3, 1e-4]}\n",
    "\n",
    "    \n",
    "    ## Defining the regressor for Kernel Ridge : Multiple output\n",
    "    mor=MultiOutputRegressor(KernelRidge())\n",
    "    clf=GridSearchCV(mor,tuned_parameters,scoring=\"neg_mean_squared_error\",cv=5).fit(A,B)#.fit(x_train, y_train)\n",
    "\n",
    "    # Getting the best parameters. estimator__gamma in this case\n",
    "    best_param=clf.cv_results_['params'][clf.best_index_]\n",
    "    nmor=MultiOutputRegressor(KernelRidge(kernel=best_param['estimator__kernel'],alpha=best_param['estimator__alpha'],gamma=best_param['estimator__gamma']))\n",
    "    \n",
    "    #Testing with full data A,B for importance\n",
    "    tlf=nmor.fit(A,B)\n",
    "    result = permutation_importance(tlf, A,B, n_repeats=5)\n",
    "    return(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ad3514e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in loop  0\n",
      "in loop  1\n",
      "in loop  2\n",
      "in loop  3\n",
      "in loop  4\n",
      "in loop  5\n",
      "in loop  6\n",
      "in loop  7\n",
      "in loop  8\n",
      "in loop  9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5.443490e-01</th>\n",
       "      <td>Asite_shannon_radii_weighted_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.343136e-01</th>\n",
       "      <td>Bsite_shannon_radii_weighted_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.720709e-01</th>\n",
       "      <td>Bsite_Ionic Radius (angstroms)_weighted_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.730565e-01</th>\n",
       "      <td>shannon_radii_AB_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.327603e-04</th>\n",
       "      <td>host_Bsite0_IsOrthorhombic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.964706e-08</th>\n",
       "      <td>Bsite_IsMetalloid_range</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.964706e-08</th>\n",
       "      <td>Bsite_IsMetalloid_max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.964706e-08</th>\n",
       "      <td>Bsite_IsMetal_range</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.434546e-08</th>\n",
       "      <td>Bsite_IsTetragonal_max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.434546e-08</th>\n",
       "      <td>Bsite_IsTetragonal_range</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "5.443490e-01             Asite_shannon_radii_weighted_avg\n",
       "5.343136e-01             Bsite_shannon_radii_weighted_avg\n",
       "3.720709e-01  Bsite_Ionic Radius (angstroms)_weighted_avg\n",
       "1.730565e-01                         shannon_radii_AB_avg\n",
       "3.327603e-04                   host_Bsite0_IsOrthorhombic\n",
       "...                                                   ...\n",
       "9.964706e-08                      Bsite_IsMetalloid_range\n",
       "9.964706e-08                        Bsite_IsMetalloid_max\n",
       "9.964706e-08                          Bsite_IsMetal_range\n",
       "3.434546e-08                       Bsite_IsTetragonal_max\n",
       "3.434546e-08                     Bsite_IsTetragonal_range\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Permutation importance code for Kernel Ridge ######\n",
    "\n",
    "# Permuting columns to ensure robustness\n",
    "l=np.random.permutation(x_screen_new.columns)\n",
    "xl=x_screen_new[l] # to permute the columns\n",
    "\n",
    "## Defining the importance array \n",
    "importance_krid=np.zeros((10,100))\n",
    "\n",
    "for i in range(0,10):\n",
    "    print(\"in loop \",i)\n",
    "    importance=kernel_rid_lanth(xl,y_scaled)\n",
    "    importance_krid[i,:]=np.transpose(importance.importances_mean)\n",
    "\n",
    "importance_rf_final=pd.DataFrame(importance_krid,columns=xl.columns)\n",
    "indx=importance_rf_final.mean(axis=0).argsort()[::-1]\n",
    "pd.DataFrame(importance_rf_final.columns[indx],importance_rf_final.mean(axis=0)[indx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb16e54a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
